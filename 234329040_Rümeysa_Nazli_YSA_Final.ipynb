{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rmynzl/calismalarim/blob/main/234329040_R%C3%BCmeysa_Nazli_YSA_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwJyQzAvTOTG"
      },
      "source": [
        "### Gerekli kÃ¼tÃ¼phaneler ve veri yÃ¼kleme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7XSp3w8kPvS",
        "outputId": "684e7a76-4b68-4354-c208-79e59e74a34f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import DenseNet121, MobileNet\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "import seaborn as sns\n",
        "\n",
        "# Mixed Precision kullanÄ±mÄ± (GPU PerformansÄ± iÃ§in)\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "\n",
        "\n",
        "# Google Drive baÄŸlÄ±yorum\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#  Veri Seti Konumu\n",
        "data_dir = '/content/drive/MyDrive/data'\n",
        "if not os.path.exists(data_dir):\n",
        "    raise FileNotFoundError(f\"Hata: {data_dir} bulunamadÄ±. DoÄŸru yolu verdiÄŸinden emin ol!\")\n",
        "\n",
        "# GÃ¶rsel boyutu ve batch size belirliyorum\n",
        "image_size = (224, 224)\n",
        "batch_size = 64\n",
        "\n",
        "# Veri artÄ±rÄ±mÄ± ve Ã¶n iÅŸleme adÄ±mÄ±\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkKszPoBd4Go"
      },
      "source": [
        "* Google Drive'dan veri setini aldÄ±m, gÃ¶rseller iÃ§in veri artÄ±rÄ±mÄ± yaptÄ±m. AyrÄ±ca, GPU performansÄ±nÄ± artÄ±rmak iÃ§in mixed precision (float16) kullandÄ±m. GÃ¶rsellerin boyutunu 224x224 olarak ayarladÄ±m ve batch size 64 olarak belirledim.  (eÄŸitim kodu yavaÅŸ Ã§alÄ±ÅŸtÄ±ÄŸÄ± iÃ§in batch size artÄ±rmak zorunda kaldÄ±m.)\n",
        "\n",
        "* 0.20 test verisi olacak ÅŸekilde ayrÄ±m yapÄ±yorum.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvqu9c1LbIQF",
        "outputId": "4d14e779-635e-408a-8ac8-173e612cf26a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6043 images belonging to 2 classes.\n",
            "Found 1510 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# EÄŸitim ve doÄŸrulama veri setlerini yÃ¼kleme\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"sparse\",\n",
        "    subset=\"training\",\n",
        "    color_mode=\"rgb\",\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"sparse\",\n",
        "    subset=\"validation\",\n",
        "    color_mode=\"rgb\",\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sJMHrT8eSm-"
      },
      "source": [
        "* Veri setlerini yÃ¼klerken, train_generator ve val_generator kullanarak eÄŸitim ve doÄŸrulama verilerini ayÄ±rÄ±yorum. Bu iÅŸlemde, datagen.flow_from_directory fonksiyonunu kullanÄ±yorum. EÄŸitim ve doÄŸrulama verisi, belirlediÄŸim data_dir dizininden yÃ¼kleniyor ve gÃ¶rÃ¼ntÃ¼ler image_size (224x224) boyutlarÄ±na getirilip, batch_size olarak 64 ile gruplanÄ±yor.\n",
        "\n",
        "* EÄŸitim verisi: 6043 adet gÃ¶rÃ¼ntÃ¼ bulunuyor ve bu gÃ¶rÃ¼ntÃ¼ler 2 farklÄ± sÄ±nÄ±fa ait.  (maskeli ve maskesiz grup)\n",
        "* DoÄŸrulama verisi: 1510 adet gÃ¶rÃ¼ntÃ¼ bulunuyor ve bunlar da 2 farklÄ± sÄ±nÄ±fa ait.  (maskeli ve maskesiz grup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkfB5jF_boNZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow.keras.applications import DenseNet121, MobileNet\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Mixed Precision kullanÄ±mÄ± (GPU PerformansÄ± iÃ§in)\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Modeli oluÅŸturma fonksiyonunu yazaluÄ±m\n",
        "def create_model(base_model_name=\"MobileNet\"):\n",
        "    if base_model_name == \"DenseNet121\":\n",
        "        base_model = DenseNet121(weights=\"imagenet\", include_top=False, input_shape=(image_size[0], image_size[1], 3))\n",
        "    elif base_model_name == \"MobileNet\":\n",
        "        base_model = MobileNet(weights=\"imagenet\", include_top=False, input_shape=(image_size[0], image_size[1], 3))\n",
        "    else:\n",
        "        raise ValueError(\"GeÃ§ersiz model adÄ±. 'DenseNet121' veya 'MobileNet' olmalÄ±.\")\n",
        "\n",
        "    # Ã–nceden eÄŸitilmiÅŸ katmanlarÄ± donduruyorum daha hÄ±zlÄ± olmasÄ± iÃ§in\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Modelin Ãœst KatmanlarÄ±nÄ± belirleyelim\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(256, activation=\"relu\")(x)\n",
        "    x = Dense(64, activation=\"relu\")(x)\n",
        "    predictions = Dense(2, activation=\"softmax\")(x)  # Binary sÄ±nÄ±flandÄ±rma iÃ§in softmax\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4N-0-w_eojt"
      },
      "source": [
        "* Mixed Precision: GPU hÄ±zlandÄ±rmasÄ± iÃ§in mixed_precision kullanarak iÅŸlem yapÄ±lan veri tipini float16 olarak ayarladÄ±m.\n",
        "\n",
        "* Model oluÅŸturma: DenseNet121 veya MobileNet bazlÄ± pre-trained modelleri seÃ§tim. Bu modellerin Ã¼st katmanlarÄ±nÄ± Ã¶zelleÅŸtirdim.\n",
        "\n",
        "* EÄŸitim iÃ§in hazÄ±r model: Pre-trained modelin katmanlarÄ±nÄ± dondurdum, ardÄ±ndan modelin Ã¼st katmanlarÄ±na dropout ve dense katmanlarÄ± ekledim. SonuÃ§ olarak iki sÄ±nÄ±flÄ± (binary) sÄ±nÄ±flandÄ±rma yapan bir model oluÅŸturmuÅŸ oldum."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyPev97CISGN"
      },
      "outputs": [],
      "source": [
        "# Modeli oluÅŸturuyorum\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model = create_model(base_model_name=\"MobileNet\")\n",
        "model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6r2V795fQ85"
      },
      "source": [
        "* Bu kodda modelimi oluÅŸturup derliyorum.\n",
        "\n",
        "* Ä°lk olarak, Adam optimizasyon yÃ¶ntemini seÃ§iyorum ve Ã¶ÄŸrenme oranÄ±nÄ±(LR) 0.001 olarak ayarlÄ±yorum.\n",
        "\n",
        "* Sonra, create_model fonksiyonu ile MobileNet tabanlÄ± modelimi oluÅŸturuyorum.\n",
        "\n",
        "* Son olarak, modelimi derlerken kayÄ±p fonksiyonu olarak sparse_categorical_crossentropy ve baÅŸarÄ± metriÄŸi olarak accuracy belirliyorum. Bu ÅŸekilde modelim eÄŸitim iÃ§in hazÄ±r hale gelmiÅŸ oluyor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhaHLJZvUA6u"
      },
      "source": [
        "### Callback tanÄ±mlama ve Model EÄŸitimi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "meXw7J0wISCv",
        "outputId": "bf683aeb-0a7c-45e7-ee12-30c36bcebff2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m24/95\u001b[0m \u001b[32mâ”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m28:12\u001b[0m 24s/step - accuracy: 0.8177 - loss: 0.3371"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25s/step - accuracy: 0.9181 - loss: 0.1682 \n",
            "Epoch 1: val_loss improved from inf to 0.08923, saving model to best_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3162s\u001b[0m 33s/step - accuracy: 0.9185 - loss: 0.1674 - val_accuracy: 0.9722 - val_loss: 0.0892 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.9852 - loss: 0.0442 \n",
            "Epoch 2: val_loss improved from 0.08923 to 0.05915, saving model to best_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1600s\u001b[0m 16s/step - accuracy: 0.9852 - loss: 0.0441 - val_accuracy: 0.9861 - val_loss: 0.0592 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.9854 - loss: 0.0463 \n",
            "Epoch 3: val_loss improved from 0.05915 to 0.03129, saving model to best_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1565s\u001b[0m 16s/step - accuracy: 0.9854 - loss: 0.0462 - val_accuracy: 0.9914 - val_loss: 0.0313 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.9874 - loss: 0.0315 \n",
            "Epoch 4: val_loss did not improve from 0.03129\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1553s\u001b[0m 16s/step - accuracy: 0.9874 - loss: 0.0315 - val_accuracy: 0.9907 - val_loss: 0.0341 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.9865 - loss: 0.0408 \n",
            "Epoch 5: val_loss improved from 0.03129 to 0.02746, saving model to best_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1584s\u001b[0m 17s/step - accuracy: 0.9865 - loss: 0.0407 - val_accuracy: 0.9881 - val_loss: 0.0275 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.9943 - loss: 0.0210 \n",
            "Epoch 6: val_loss did not improve from 0.02746\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1584s\u001b[0m 17s/step - accuracy: 0.9942 - loss: 0.0210 - val_accuracy: 0.9887 - val_loss: 0.0307 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.9916 - loss: 0.0259 \n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.02746\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1570s\u001b[0m 17s/step - accuracy: 0.9916 - loss: 0.0260 - val_accuracy: 0.9894 - val_loss: 0.0403 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.9930 - loss: 0.0176 "
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "# ðŸ“Œ Callbacks tanÄ±mlayalÄ±m\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1)\n",
        "lr_reduction = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=2, verbose=1)\n",
        "checkpoint = ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_loss\", verbose=1)\n",
        "\n",
        "# ðŸ“Œ Modeli EÄŸitelim\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[early_stopping, lr_reduction, checkpoint],\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hQDYOFFISBY"
      },
      "outputs": [],
      "source": [
        "# EÄŸitim ve doÄŸrulama doÄŸruluÄŸu/grafiÄŸi Ã§izdirelim\n",
        "\n",
        "def plot_learning_curves(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.legend()\n",
        "    plt.title('Accuracy')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Loss')\n",
        "    plt.show()\n",
        "\n",
        "plot_learning_curves(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf3SyDuGfu5I"
      },
      "source": [
        "* Burada, eÄŸitim sÃ¼recindeki doÄŸruluk (accuracy) ve kayÄ±p (loss) deÄŸerlerini gÃ¶rselleÅŸtiriyoruz.\n",
        "\n",
        "* Ä°lki, eÄŸitim doÄŸruluÄŸunu (accuracy) gÃ¶steriyor. Ä°kincisi ise eÄŸitim kaybÄ± (loss) ile doÄŸrulama kaybÄ±nÄ± (val_loss) karÅŸÄ±laÅŸtÄ±rÄ±yor.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK_1s3h8TKip"
      },
      "source": [
        "### DeÄŸerlendirme AÅŸamalarÄ±\n",
        "\n",
        "> Blok alÄ±ntÄ± ekle\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1qOZRA6IRe-"
      },
      "outputs": [],
      "source": [
        "# Test set ile deÄŸerlendirme yapalÄ±m\n",
        "X_test, y_test = next(val_generator)\n",
        "predictions = model.predict(X_test)\n",
        "y_pred = np.argmax(predictions, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJBZhTXSI5sk"
      },
      "outputs": [],
      "source": [
        "# KarÄ±ÅŸÄ±klÄ±k Matrisi\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5yCLXI3I9iT"
      },
      "outputs": [],
      "source": [
        "# ROC EÄŸrisi\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, predictions[:, 1])\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.plot(fpr, tpr, label='AUC = {:.3f}'.format(roc_auc))\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.title('ROC Curve')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Performans Metrikleri\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMChFhzJUBo5XpHzMrl/AQo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}