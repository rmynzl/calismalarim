{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rmynzl/calismalarim/blob/main/234329040_R%C3%BCmeysa_Nazli_YSA_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwJyQzAvTOTG"
      },
      "source": [
        "### Gerekli kütüphaneler ve veri yükleme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7XSp3w8kPvS",
        "outputId": "684e7a76-4b68-4354-c208-79e59e74a34f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import DenseNet121, MobileNet\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "import seaborn as sns\n",
        "\n",
        "# Mixed Precision kullanımı (GPU Performansı için)\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "\n",
        "\n",
        "# Google Drive bağlıyorum\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#  Veri Seti Konumu\n",
        "data_dir = '/content/drive/MyDrive/data'\n",
        "if not os.path.exists(data_dir):\n",
        "    raise FileNotFoundError(f\"Hata: {data_dir} bulunamadı. Doğru yolu verdiğinden emin ol!\")\n",
        "\n",
        "# Görsel boyutu ve batch size belirliyorum\n",
        "image_size = (224, 224)\n",
        "batch_size = 64\n",
        "\n",
        "# Veri artırımı ve ön işleme adımı\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkKszPoBd4Go"
      },
      "source": [
        "* Google Drive'dan veri setini aldım, görseller için veri artırımı yaptım. Ayrıca, GPU performansını artırmak için mixed precision (float16) kullandım. Görsellerin boyutunu 224x224 olarak ayarladım ve batch size 64 olarak belirledim.  (eğitim kodu yavaş çalıştığı için batch size artırmak zorunda kaldım.)\n",
        "\n",
        "* 0.20 test verisi olacak şekilde ayrım yapıyorum.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvqu9c1LbIQF",
        "outputId": "4d14e779-635e-408a-8ac8-173e612cf26a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6043 images belonging to 2 classes.\n",
            "Found 1510 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Eğitim ve doğrulama veri setlerini yükleme\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"sparse\",\n",
        "    subset=\"training\",\n",
        "    color_mode=\"rgb\",\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"sparse\",\n",
        "    subset=\"validation\",\n",
        "    color_mode=\"rgb\",\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sJMHrT8eSm-"
      },
      "source": [
        "* Veri setlerini yüklerken, train_generator ve val_generator kullanarak eğitim ve doğrulama verilerini ayırıyorum. Bu işlemde, datagen.flow_from_directory fonksiyonunu kullanıyorum. Eğitim ve doğrulama verisi, belirlediğim data_dir dizininden yükleniyor ve görüntüler image_size (224x224) boyutlarına getirilip, batch_size olarak 64 ile gruplanıyor.\n",
        "\n",
        "* Eğitim verisi: 6043 adet görüntü bulunuyor ve bu görüntüler 2 farklı sınıfa ait.  (maskeli ve maskesiz grup)\n",
        "* Doğrulama verisi: 1510 adet görüntü bulunuyor ve bunlar da 2 farklı sınıfa ait.  (maskeli ve maskesiz grup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkfB5jF_boNZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow.keras.applications import DenseNet121, MobileNet\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Mixed Precision kullanımı (GPU Performansı için)\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Modeli oluşturma fonksiyonunu yazaluım\n",
        "def create_model(base_model_name=\"MobileNet\"):\n",
        "    if base_model_name == \"DenseNet121\":\n",
        "        base_model = DenseNet121(weights=\"imagenet\", include_top=False, input_shape=(image_size[0], image_size[1], 3))\n",
        "    elif base_model_name == \"MobileNet\":\n",
        "        base_model = MobileNet(weights=\"imagenet\", include_top=False, input_shape=(image_size[0], image_size[1], 3))\n",
        "    else:\n",
        "        raise ValueError(\"Geçersiz model adı. 'DenseNet121' veya 'MobileNet' olmalı.\")\n",
        "\n",
        "    # Önceden eğitilmiş katmanları donduruyorum daha hızlı olması için\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Modelin Üst Katmanlarını belirleyelim\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(256, activation=\"relu\")(x)\n",
        "    x = Dense(64, activation=\"relu\")(x)\n",
        "    predictions = Dense(2, activation=\"softmax\")(x)  # Binary sınıflandırma için softmax\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4N-0-w_eojt"
      },
      "source": [
        "* Mixed Precision: GPU hızlandırması için mixed_precision kullanarak işlem yapılan veri tipini float16 olarak ayarladım.\n",
        "\n",
        "* Model oluşturma: DenseNet121 veya MobileNet bazlı pre-trained modelleri seçtim. Bu modellerin üst katmanlarını özelleştirdim.\n",
        "\n",
        "* Eğitim için hazır model: Pre-trained modelin katmanlarını dondurdum, ardından modelin üst katmanlarına dropout ve dense katmanları ekledim. Sonuç olarak iki sınıflı (binary) sınıflandırma yapan bir model oluşturmuş oldum."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyPev97CISGN"
      },
      "outputs": [],
      "source": [
        "# Modeli oluşturuyorum\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model = create_model(base_model_name=\"MobileNet\")\n",
        "model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6r2V795fQ85"
      },
      "source": [
        "* Bu kodda modelimi oluşturup derliyorum.\n",
        "\n",
        "* İlk olarak, Adam optimizasyon yöntemini seçiyorum ve öğrenme oranını(LR) 0.001 olarak ayarlıyorum.\n",
        "\n",
        "* Sonra, create_model fonksiyonu ile MobileNet tabanlı modelimi oluşturuyorum.\n",
        "\n",
        "* Son olarak, modelimi derlerken kayıp fonksiyonu olarak sparse_categorical_crossentropy ve başarı metriği olarak accuracy belirliyorum. Bu şekilde modelim eğitim için hazır hale gelmiş oluyor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhaHLJZvUA6u"
      },
      "source": [
        "### Callback tanımlama ve Model Eğitimi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "meXw7J0wISCv",
        "outputId": "bf683aeb-0a7c-45e7-ee12-30c36bcebff2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m24/95\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28:12\u001b[0m 24s/step - accuracy: 0.8177 - loss: 0.3371"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25s/step - accuracy: 0.9181 - loss: 0.1682 \n",
            "Epoch 1: val_loss improved from inf to 0.08923, saving model to best_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3162s\u001b[0m 33s/step - accuracy: 0.9185 - loss: 0.1674 - val_accuracy: 0.9722 - val_loss: 0.0892 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.9852 - loss: 0.0442 \n",
            "Epoch 2: val_loss improved from 0.08923 to 0.05915, saving model to best_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1600s\u001b[0m 16s/step - accuracy: 0.9852 - loss: 0.0441 - val_accuracy: 0.9861 - val_loss: 0.0592 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.9854 - loss: 0.0463 \n",
            "Epoch 3: val_loss improved from 0.05915 to 0.03129, saving model to best_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1565s\u001b[0m 16s/step - accuracy: 0.9854 - loss: 0.0462 - val_accuracy: 0.9914 - val_loss: 0.0313 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.9874 - loss: 0.0315 \n",
            "Epoch 4: val_loss did not improve from 0.03129\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1553s\u001b[0m 16s/step - accuracy: 0.9874 - loss: 0.0315 - val_accuracy: 0.9907 - val_loss: 0.0341 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.9865 - loss: 0.0408 \n",
            "Epoch 5: val_loss improved from 0.03129 to 0.02746, saving model to best_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1584s\u001b[0m 17s/step - accuracy: 0.9865 - loss: 0.0407 - val_accuracy: 0.9881 - val_loss: 0.0275 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.9943 - loss: 0.0210 \n",
            "Epoch 6: val_loss did not improve from 0.02746\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1584s\u001b[0m 17s/step - accuracy: 0.9942 - loss: 0.0210 - val_accuracy: 0.9887 - val_loss: 0.0307 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.9916 - loss: 0.0259 \n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.02746\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1570s\u001b[0m 17s/step - accuracy: 0.9916 - loss: 0.0260 - val_accuracy: 0.9894 - val_loss: 0.0403 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.9930 - loss: 0.0176 "
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "# 📌 Callbacks tanımlayalım\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1)\n",
        "lr_reduction = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=2, verbose=1)\n",
        "checkpoint = ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_loss\", verbose=1)\n",
        "\n",
        "# 📌 Modeli Eğitelim\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[early_stopping, lr_reduction, checkpoint],\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hQDYOFFISBY"
      },
      "outputs": [],
      "source": [
        "# Eğitim ve doğrulama doğruluğu/grafiği çizdirelim\n",
        "\n",
        "def plot_learning_curves(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.legend()\n",
        "    plt.title('Accuracy')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Loss')\n",
        "    plt.show()\n",
        "\n",
        "plot_learning_curves(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf3SyDuGfu5I"
      },
      "source": [
        "* Burada, eğitim sürecindeki doğruluk (accuracy) ve kayıp (loss) değerlerini görselleştiriyoruz.\n",
        "\n",
        "* İlki, eğitim doğruluğunu (accuracy) gösteriyor. İkincisi ise eğitim kaybı (loss) ile doğrulama kaybını (val_loss) karşılaştırıyor.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK_1s3h8TKip"
      },
      "source": [
        "### Değerlendirme Aşamaları\n",
        "\n",
        "> Blok alıntı ekle\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1qOZRA6IRe-"
      },
      "outputs": [],
      "source": [
        "# Test set ile değerlendirme yapalım\n",
        "X_test, y_test = next(val_generator)\n",
        "predictions = model.predict(X_test)\n",
        "y_pred = np.argmax(predictions, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJBZhTXSI5sk"
      },
      "outputs": [],
      "source": [
        "# Karışıklık Matrisi\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5yCLXI3I9iT"
      },
      "outputs": [],
      "source": [
        "# ROC Eğrisi\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, predictions[:, 1])\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.plot(fpr, tpr, label='AUC = {:.3f}'.format(roc_auc))\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.title('ROC Curve')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Performans Metrikleri\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMChFhzJUBo5XpHzMrl/AQo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}